
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Hadoop 集群安装详细步骤 - 研究研究</title>
  <meta name="author" content="soulmachine">

  
  <meta name="description" content="本文所使用的版本是 hadoop 1.0.0，即 2011年12月27日发布的1.0正式版。 详细安装步骤如下，有大步骤，每个步骤里面有小步骤，绝大部分是必选，只有2步是可选的，粗体表示要特别注意的地方。 1. 用vmware workstation 新建三台虚拟机 首先用vmware &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.yanjiuyanjiu.com/blog/20120103">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="研究研究" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!-- <link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"> -->
<!-- <link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"> -->

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-7583537-4']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">研究研究</a></h1>
  
    <h2>专注于机器学习</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:www.yanjiuyanjiu.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Home</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/about/">About</a></li>
  <li><a href="/notes/">读书笔记</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Hadoop 集群安装详细步骤</h1>
    
    
      <p class="meta">
        








  


<time datetime="2012-01-03T18:54:00+08:00" pubdate data-updated="true">Jan 3<span>rd</span>, 2012</time>
        
		
         | <a href="#duoshuo_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>本文所使用的版本是 hadoop 1.0.0，即 <a href="http://www.iteye.com/news/23874">2011年12月27日发布的1.0正式版</a>。</p>

<p>详细安装步骤如下，有大步骤，每个步骤里面有小步骤，绝大部分是必选，只有2步是可选的，粗体表示要特别注意的地方。</p>

<h2>1. 用vmware workstation 新建三台虚拟机</h2>

<p>首先用vmware workstation 新建一台ubuntu server，装好操作系统，安装各种必须的软件，包括安装好hadoop。安装好后然后用浅拷贝<code>Create a linked clone</code> 克隆出两台作为slave，这样有了三台ubuntu机器。启动三台机器，假设IP分别为<code>192.168.1.131, 192.168.1.132, 192.168.1.133</code>, 131做为master,132为 slave01, 133为slave02。</p>

<h2>2. 修改机器名</h2>

<p>这一步的作用是让命令行提示看起来好看点，由默认的 dev@bogon变为 dev@master，这步可选，optional，可以跳过。</p>

<ul>
<li>192.168.1.131上执行</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@bogon:~<span class="nv">$ </span>sudo vi /etc/hostname
</span></code></pre></td></tr></table></div></figure>


<p>输入<code>master</code>，重启，会发现命令提示符变为了 <code>dev@master:~$</code></p>

<ul>
<li>192.168.1.132上执行</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@bogon:~<span class="nv">$ </span>sudo vi /etc/hostname
</span></code></pre></td></tr></table></div></figure>


<p>输入<code>slave01</code>，重启，会发现命令提示符变为了 <code>dev@slave01:~$</code></p>

<ul>
<li>192.168.1.133上执行</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@bogon:~<span class="nv">$ </span>sudo vi /etc/hostname
</span></code></pre></td></tr></table></div></figure>


<p>输入<code>slave02</code>，重启，会发现命令提示符变为了 <code>dev@slave02:~$</code></p>

<!-- more -->


<h2>3. 修改master的hosts文件，并拷贝到每台slave上</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~<span class="nv">$ </span>sudo vi /etc/hosts
</span></code></pre></td></tr></table></div></figure>


<p>添加三行内容</p>

<blockquote><p>192.168.1.131 master<br/>
192.168.1.133 slave01<br/>
192.168.1.134 slave02</p></blockquote>

<p><strong>注意一定要注释掉</strong></p>

<blockquote><p># 127.0.1.1      bogon.localdomain       bogon</p></blockquote>

<p>最后hosts文件内容如下：</p>

<blockquote><p>127.0.0.1       localhost
# 127.0.1.1      bogon.localdomain       bogon
192.168.1.131 master
192.168.1.133 slave01
192.168.1.134 slave02
# The following lines are desirable for IPv6 capable hosts
::1     ip6-localhost ip6-loopback
fe00::0 ip6-localnet
ff00::0 ip6-mcastprefix
ff02::1 ip6-allnodes
ff02::2 ip6-allrouters</p></blockquote>

<ul>
<li>将hosts文件拷贝到另外两台台机器上，覆盖原来的hosts文件</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~<span class="nv">$ </span>scp /etc/hosts dev@192.168.1.132:~
</span><span class='line'>
</span><span class='line'>dev@master:~<span class="nv">$ </span>scp /etc/hosts dev@192.168.1.133:~
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>在192.168.1.132上执行</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@slave01:~<span class="nv">$ </span>sudo mv hosts /etc/hosts
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>在192.168.1.133上执行</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@slave02:~<span class="nv">$ </span>sudo mv hosts /etc/hosts
</span></code></pre></td></tr></table></div></figure>


<h2>4. 配置 master 无密码登陆到所有机器（<strong>包括本机</strong>）</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~<span class="nv">$ </span>ssh-keygen -t rsa
</span><span class='line'>
</span><span class='line'>dev@master:~<span class="nv">$ </span>cat .ssh/id_rsa.pub &gt;&gt; .ssh/authorized_keys
</span><span class='line'>
</span><span class='line'>dev@master:~<span class="nv">$ </span>scp .ssh/id_rsa.pub dev@192.168.1.132:~/
</span><span class='line'>
</span><span class='line'>dev@master:~<span class="nv">$ </span>scp .ssh/id_rsa.pub dev@192.168.1.133:~/
</span><span class='line'>
</span><span class='line'>dev@slave01:~<span class="nv">$ </span>cat id_rsa.pub &gt;&gt; .ssh/authorized_keys
</span><span class='line'>
</span><span class='line'>dev@slave02:~<span class="nv">$ </span>cat id_rsa.pub &gt;&gt; .ssh/authorized_keys
</span></code></pre></td></tr></table></div></figure>


<p>测试一下，</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~<span class="nv">$ </span>ssh slav01
</span></code></pre></td></tr></table></div></figure>


<p>如果登陆不上，试试先关闭slave01的防火墙，</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@slave01:~<span class="nv">$ </span>sudo ufw disable
</span></code></pre></td></tr></table></div></figure>


<h2>5. 复制hadoop安装包到所有机器</h2>

<p>从hadoop.apache.org下载 hadoop-1.0.0-bin.tar.gz，上传到master中，解压，然后复制到其他机器，解压。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~<span class="nv">$ </span>tar -zxvf hadoop-1.0.0-bin.tar.gz
</span><span class='line'>
</span><span class='line'>dev@master:~<span class="nv">$ </span>scp hadoop-1.0.0-bin.tar.gz dev@192.168.1.133:~
</span><span class='line'>
</span><span class='line'>dev@master:~<span class="nv">$ </span>scp hadoop-1.0.0-bin.tar.gz dev@192.168.1.134:~
</span><span class='line'>
</span><span class='line'>dev@slave01:~<span class="nv">$ </span>tar -zxvf hadoop-1.0.0-bin.tar.gz
</span><span class='line'>
</span><span class='line'>dev@slave02:~<span class="nv">$ </span>tar -zxvf hadoop-1.0.0-bin.tar.gz
</span></code></pre></td></tr></table></div></figure>


<h2>6. 编辑配置文件</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~<span class="nv">$ </span><span class="nb">cd </span>hadoop-1.0.0/etc/hadoop
</span><span class='line'>
</span><span class='line'>dev@master:~/hadoop-1.0.0/etc/hadoop<span class="nv">$ </span> vi hadoop-env.sh
</span></code></pre></td></tr></table></div></figure>


<p>仅需要设置JAVA_HOME，</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'><span class="nb">export </span><span class="nv">JAVA_HOME</span><span class="o">=</span>/usr/lib/jvm/java-7-openjdk-i386
</span><span class='line'>
</span><span class='line'>dev@master:~/hadoop-1.0.0/etc/hadoop<span class="nv">$ </span> vi core-site.xml
</span></code></pre></td></tr></table></div></figure>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;configuration&gt;</span>
</span><span class='line'><span class="nt">&lt;property&gt;</span>
</span><span class='line'><span class="nt">&lt;name&gt;</span>fs.default.name<span class="nt">&lt;/name&gt;</span>
</span><span class='line'><span class="nt">&lt;value&gt;</span>hdfs://master:9000<span class="nt">&lt;/value&gt;</span>
</span><span class='line'><span class="nt">&lt;/property&gt;</span>
</span><span class='line'><span class="nt">&lt;property&gt;</span>
</span><span class='line'><span class="nt">&lt;name&gt;</span>hadoop.tmp.dir<span class="nt">&lt;/name&gt;</span>
</span><span class='line'><span class="nt">&lt;value&gt;</span>/home/dev/hadoop_tmp/<span class="nt">&lt;/value&gt;</span>
</span><span class='line'><span class="nt">&lt;/property&gt;</span>
</span><span class='line'><span class="nt">&lt;/configuration&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~/hadoop-1.0.0/etc/hadoop<span class="nv">$ </span> vi mapred-site.xml
</span></code></pre></td></tr></table></div></figure>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;configuration&gt;</span>
</span><span class='line'><span class="nt">&lt;property&gt;</span>
</span><span class='line'><span class="nt">&lt;name&gt;</span>mapred.job.tracker<span class="nt">&lt;/name&gt;</span>
</span><span class='line'><span class="nt">&lt;value&gt;</span>master:9001<span class="nt">&lt;/value&gt;</span>
</span><span class='line'><span class="nt">&lt;/property&gt;</span>
</span><span class='line'><span class="nt">&lt;/configuration&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~/hadoop-1.0.0/etc/hadoop<span class="nv">$ </span> vi hdfs-site.xml
</span></code></pre></td></tr></table></div></figure>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='xml'><span class='line'><span class="nt">&lt;configuration&gt;</span>
</span><span class='line'><span class="nt">&lt;property&gt;</span>
</span><span class='line'><span class="nt">&lt;name&gt;</span>dfs.replication<span class="nt">&lt;/name&gt;</span>
</span><span class='line'><span class="nt">&lt;value&gt;</span>3<span class="nt">&lt;/value&gt;</span>
</span><span class='line'><span class="nt">&lt;/property&gt;</span>
</span><span class='line'><span class="nt">&lt;/configuration&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~/hadoop-1.0.0/etc/hadoop<span class="nv">$ </span> vi masters
</span><span class='line'>
</span><span class='line'>192.168.1.133
</span><span class='line'>
</span><span class='line'>dev@master:~/hadoop-1.0.0/etc/hadoop<span class="nv">$ </span> vi slaves
</span><span class='line'>
</span><span class='line'>192.168.1.133
</span><span class='line'>
</span><span class='line'>192.168.1.134
</span></code></pre></td></tr></table></div></figure>


<h2>7. 将配置文件拷贝到各台slave</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~/hadoop-1.0.0/etc/hadoop<span class="nv">$ </span>scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves dev@192.168.1.133:~/hadoop-1.0.0/etc/hadoop
</span><span class='line'>
</span><span class='line'>dev@master:~/hadoop-1.0.0/etc/hadoop<span class="nv">$ </span>scp hadoop-env.sh core-site.xml hdfs-site.xml mapred-site.xml masters slaves dev@192.168.1.134:~/hadoop-1.0.0/etc/hadoop
</span></code></pre></td></tr></table></div></figure>


<p>（master和slaves这2个配置文件可以不拷贝到slave机器上，只在master上保存即可。待验证）</p>

<h2>8. 设置环境变量</h2>

<ul>
<li>设置master的环境变量</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~<span class="nv">$ </span>vi .bashrc
</span><span class='line'>
</span><span class='line'><span class="nb">export </span><span class="nv">JAVA_HOME</span><span class="o">=</span>/usr/lib/jvm/java-7-openjdk-i386
</span><span class='line'><span class="nb">export </span><span class="nv">CLASSPATH</span><span class="o">=</span><span class="nv">$JAVA_HOME</span>/lib/dt.jar:<span class="nv">$JAVA_HOME</span>/lib/tools.jar
</span><span class='line'><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$JAVA_HOME</span>/bin
</span><span class='line'><span class="nb">export </span><span class="nv">HADOOP_HOME</span><span class="o">=</span>~/hadoop-1.0.0
</span><span class='line'><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$HADOOP_HOME</span>/bin:<span class="nv">$HADOOP_HOME</span>/sbin
</span><span class='line'><span class="nb">export </span><span class="nv">CLASSPATH</span><span class="o">=</span><span class="nv">$CLASSPATH</span>:<span class="nv">$HADOOP_HOME</span>/share/hadoop/hadoop-core-1.0.0.jar
</span><span class='line'>
</span><span class='line'><span class="nb">export </span><span class="nv">HADOOP_HOME</span><span class="o">=</span>~/hadoop-1.0.0
</span><span class='line'>
</span><span class='line'><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="nv">$PATH</span>:<span class="nv">$HADOOP_HOME</span>/bin
</span><span class='line'>
</span><span class='line'>dev@master:~<span class="nv">$ </span><span class="nb">source</span> .bashrc
</span></code></pre></td></tr></table></div></figure>


<ul>
<li>将master上的.bashrc拷贝到其他机器，并source刷新。</li>
</ul>


<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~<span class="nv">$ </span>scp .bashrc dev@192.168.1.133:~
</span><span class='line'>
</span><span class='line'>dev@master:~<span class="nv">$ </span>scp .bashrc dev@192.168.1.134:~
</span><span class='line'>
</span><span class='line'>dev@slave01:~<span class="nv">$ </span><span class="nb">source</span> .bashrc
</span><span class='line'>
</span><span class='line'>dev@slave02:~<span class="nv">$ </span><span class="nb">source</span> .bashrc
</span></code></pre></td></tr></table></div></figure>


<h2>9. 运行 hadoop</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~<span class="nv">$ </span>hadoop  namenode -format  （只需一次，下次启动不再需要格式化，只需 start-all.sh）
</span><span class='line'>
</span><span class='line'>dev@master:~<span class="nv">$ </span>start-all.sh
</span></code></pre></td></tr></table></div></figure>


<h2>10. 检查是否运行成功</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~<span class="nv">$ </span>jps
</span><span class='line'>
</span><span class='line'>2615 NameNode
</span><span class='line'>2767 JobTracker
</span><span class='line'>2874 Jps
</span><span class='line'>
</span><span class='line'>dev@slave01:~<span class="nv">$ </span>jps
</span><span class='line'>
</span><span class='line'>3415 DataNode
</span><span class='line'>3582 TaskTracker
</span><span class='line'>3499 SecondaryNameNode
</span><span class='line'>3619 Jps
</span><span class='line'>
</span><span class='line'>dev@slave02:~<span class="nv">$ </span>jps
</span><span class='line'>
</span><span class='line'>3741 Jps
</span><span class='line'>3618 DataNode
</span><span class='line'>3702 TaskTracker
</span></code></pre></td></tr></table></div></figure>


<h2>11. 停止 hadoop集群</h2>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='bash'><span class='line'>dev@master:~<span class="nv">$ </span>stop-all.sh
</span></code></pre></td></tr></table></div></figure>


<p>让 slave 节点也 可以启动 整个hadoop集群</p>

<h2>注意</h2>

<ol>
<li><p>stat-all.sh 启动后，刚刚开始，namenode的日志里有些异常，是正常的，过一两分钟就好了，如果两分钟后，还有异常不断在打印，就有问题了。datanode的日志，从一开始，正常情况下，就没有异常，如果报了异常，说明有异常，要去排除。</p></li>
<li><p>masters文件，这个文件很容易被误解，它实际上存放的是secondarynamenode，而不是namenode。</p>

<blockquote><p>An HDFS instance is started on a cluster by logging in to the NameNode machine and running$HADOOP_HOME/bin/start-dfs.sh (orstart-all.sh ). This script. starts a local instance of the NameNode process, logs into every machine listed in theconf/slaves file and starts an instance of the DataNode process, and logs into every machine listed in theconf/masters file and starts an instance of the SecondaryNameNode process. Themasters file does not govern which nodes become NameNodes or JobTrackers; those are started on the machine(s) wherebin/start-dfs.sh andbin/start-mapred.sh are executed. A more accurate filename might be “secondaries,” but that’s not currently the case.</p></blockquote>

<p> 参考以下三篇文章：
 <a href="http://www.cloudera.com/blog/2009/02/multi-host-secondarynamenode-configuration/">Multi-host SecondaryNameNode Configuration</a><br/>
 <a href="http://blog.csdn.net/dajuezhao/article/details/5987580">SecondaryNamenode应用摘记</a>
 <a href="http://blog.csdn.net/AE86_FC/article/details/5284181">hadoop下运行多个SecondaryNameNode的配置</a></p></li>
<li><p>一定要注释掉 hosts里面的 <code>#127.0.1.1      bogon.localdomain       bogon</code>，参考 <a href="http://blog.sina.com.cn/s/blog_631ffec50100w700.html">Hadoop集群机器命名机制</a>，<a href="http://blog.csdn.net/singno116/article/details/6298995">hadoop集群环境安装中的hosts 配置问题</a>。</p></li>
<li><p>当测试ssh是否能连通时，如果连接不上，先记得要关闭防火墙，<code>sudo ufw disable</code>，参考<a href="http://blog.csdn.net/make19830723/article/details/6230074">hadoop集群安装步骤</a>。</p></li>
</ol>


<h2>未解决的疑惑</h2>

<ol>
<li>有的很多文章，比如这篇，<a href="http://blog.csdn.net/cuishi0/article/details/6824884">Hadoop集群安装</a>，在core-site.xml, mapred-site.xml，直接写上ip:port，这样就不用修改hosts文件了。可是我这样配置，老是不成功。为此我还<a href="http://stackoverflow.com/questions/8702637/hadoop-conf-fs-default-name-cant-be-setted-ipport-format-directly">在stackoverflow上发了帖子</a>。<a href="http://51mst.iteye.com/blog/1152439">这篇文章</a>又说只能用host:port的形式。因此ip:port的格式是否能成功还待验证。如果有高手用ip:port配置成功过，请在下面留言或给我发email，一起交流:)</li>
</ol>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">soulmachine</span></span>

      








  


<time datetime="2012-01-03T18:54:00+08:00" pubdate data-updated="true">Jan 3<span>rd</span>, 2012</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/cloud/'>cloud</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <!-- JiaThis Button BEGIN -->
<div class="jiathis_style_24x24">
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_renren"></a>
	<a class="jiathis_button_kaixin001"></a>
	<a href="http://www.jiathis.com/share?uid=901902" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript">
var jiathis_config = {data_track_clickback:'true'};
</script>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=901902" charset="utf-8"></script>
<!-- JiaThis Button END -->
  
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/20110623/" title="Previous Post: 用javac命令行编译多个java文件">&laquo; 用javac命令行编译多个java文件</a>
      
      
        <a class="basic-alignment right" href="/blog/20120418/" title="Next Post: 制作 VMware ESXI 5 U盘安装盘">制作 VMware ESXI 5 U盘安装盘 &raquo;</a>
      
    </p>
  </footer>
</article>


  <section>
    <h1>Comments</h1>
    <div id="duoshuo_thread" aria-live="polite"><!-- Duoshuo Comment BEGIN -->
	<div class="ds-thread"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"yanjiuyanjiu"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- Duoshuo Comment END --></div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>About Me</h1>
  <p>在清华大学读研，目前正在研究机器学习，每周在清华举办读书会，欢迎大家前来交流切磋.</p>
  <p>新浪微博: <a href="http://weibo.com/soulmachine">@soulmachine</a><br/>
     Twitter: <a href="https://twitter.com/#!/soulmachine">@soulmachine</a><br/>
     Other: <a href="https://github.com/soulmachine">Github</a>, <a href="https://plus.google.com/103519507226474510310">Google+</a>, <a href="http://www.linkedin.com/in/soulmachine">LinkedIn</a>, <a href="http://www.quora.com/Jason-Day-2">Quora</a></p>
  </p>
</section>
<section>
  <h1>最新文章</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/20130402/">我的Octopress配置</a>
      </li>
    
      <li class="post">
        <a href="/blog/20130401/">使用github + Octopress 搭建免费博客</a>
      </li>
    
      <li class="post">
        <a href="/blog/20130327/">机器学习的一些通俗易懂的tutorial</a>
      </li>
    
      <li class="post">
        <a href="/blog/20130322/">一些主流的编程竞赛网站</a>
      </li>
    
      <li class="post">
        <a href="/blog/20130226/">数值计算库与科学计算库</a>
      </li>
    
  </ul>
</section>
<section>
  <h1>分类目录</h1>
    <ul id="category-list"><li><a href='/blog/categories/algorithm/'>algorithm (1)</a></li><li><a href='/blog/categories/cloud/'>cloud (1)</a></li><li><a href='/blog/categories/language/'>language (2)</a></li><li><a href='/blog/categories/machine-learning/'>machine-learning (4)</a></li><li><a href='/blog/categories/tools/'>tools (9)</a></li></ul>
</section>
<section>
  <h1>友情链接</h1>
  <ul>
    <li>
      <a href="http://yewen.us/" title="大学同学，ACM高手，曾在百度，现在人人网">笨狗随手留下</a>
    </li>
    <li>
      <a href="http://blog.csdn.net/lgnlgn" title="好朋友，曾在赶集网，现在老家的猫扑">梁兄的技术博客</a>
    </li>
    <li>
      <a href="http://www.doesbetter.com/" title="一起组织机器学习读书会的好朋友">王孝舒的博客</a>
    </li>
    <li>
      <a href="http://www.wytk2008.net/" title="做机器学习的一位同学">无垠天空</a>
    </li>
  </ul>
</section>




<section>
<h1>最新评论</h1>
<ul class="ds-recent-comments" data-num-items="5" data-show-avatars="1" data-show-time="1" data-show-title="1" data-show-admin="0" data-excerpt-length="32"></ul>

</section>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
<p>
  Copyright &copy; 2013 - soulmachine -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
